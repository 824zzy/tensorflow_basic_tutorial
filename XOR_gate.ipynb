{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class FNN(object):\n",
    "    \"\"\"Build a general FeedForward neural network\n",
    "    Parameters\n",
    "    ----------\n",
    "    learning_rate : float\n",
    "    drop_out : float\n",
    "    Layers : list\n",
    "        The number of layers\n",
    "    N_hidden : list\n",
    "        The numbers of nodes in layers\n",
    "    D_input : int\n",
    "        Input dimension\n",
    "    D_label : int\n",
    "        Label dimension\n",
    "    Task_type : string\n",
    "        'regression' or 'classification'\n",
    "    L2_lambda : float\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, learning_rate, drop_keep, Layers, N_hidden, D_input, D_label, Task_type='regression', L2_lambda=0.0):\n",
    "        \n",
    "        #var\n",
    "        self.learning_rate = learning_rate\n",
    "        self.drop_keep = np.array(drop_keep).astype(np.float32)\n",
    "        self.Layers = Layers\n",
    "        self.N_hidden = N_hidden\n",
    "        self.D_input = D_input\n",
    "        self.D_label = D_label\n",
    "        self.Task_type = Task_type\n",
    "        self.L2_lambda = L2_lambda\n",
    "        \n",
    "        # Placeholders\n",
    "        self.inputs = tf.placeholder(tf.float32, [None, D_input], name=\"inputs\")\n",
    "        self.labels = tf.placeholder(tf.float32, [None, D_label], name=\"labels\")\n",
    "        self.drop_keep_rate = tf.placeholder(tf.float32, name=\"dropout_keep\")\n",
    "        \n",
    "        # accumulate l2 regularization\n",
    "        self.l2_penalty = tf.constant(0.0)\n",
    "        \n",
    "        self.build('FNN')\n",
    "        \n",
    "    def weight_init(self,shape):\n",
    "        # shape : list [in_dim, out_dim]\n",
    "        # can change initialization here\n",
    "        initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "        return tf.Variable(initial)\n",
    "\n",
    "    def bias_init(self,shape):\n",
    "        # can change initialization here\n",
    "        initial = tf.constant(0.1, shape=shape)\n",
    "        return tf.Variable(initial)\n",
    "    \n",
    "    def variable_summaries(self, var, name):\n",
    "        with tf.name_scope(name+'summaries'):\n",
    "            mean = tf.reduce_mean(var)\n",
    "            tf.scalar_summary('mean/' + name, mean)\n",
    "        with tf.name_scope(name+'stddev'):\n",
    "            stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "        tf.scalar_summary('stddev/' + name, stddev)\n",
    "        tf.scalar_summary('max/' + name, tf.reduce_max(var))\n",
    "        tf.scalar_summary('min/' + name, tf.reduce_min(var))\n",
    "        tf.histogram_summary(name, var)\n",
    "\n",
    "    def layer(self,in_tensor, in_dim, out_dim, layer_name, act=tf.nn.relu):\n",
    "        with tf.name_scope(layer_name):\n",
    "            with tf.name_scope(layer_name+'weights'):\n",
    "                weights = self.weight_init([in_dim, out_dim])\n",
    "                self.variable_summaries(weights, layer_name + '/weights')\n",
    "            with tf.name_scope(layer_name+'biases'):\n",
    "                biases = self.bias_init([out_dim])\n",
    "                self.variable_summaries(biases, layer_name + '/biases')\n",
    "            with tf.name_scope(layer_name+'Wx_plus_b'):\n",
    "                pre_activate = tf.matmul(in_tensor, weights) + biases\n",
    "                tf.histogram_summary(layer_name + '/pre_activations', pre_activate)\n",
    "            activations = act(pre_activate, name='activation')\n",
    "            tf.histogram_summary(layer_name + '/activations', activations)\n",
    "        return activations, tf.nn.l2_loss(weights)\n",
    "\n",
    "    def drop_layer(self,in_tensor):\n",
    "            #tf.scalar_summary('dropout_keep', self.drop_keep_rate)\n",
    "        dropped = tf.nn.dropout(in_tensor, self.drop_keep_rate)\n",
    "        return dropped\n",
    "\n",
    "    def build(self, prefix):\n",
    "        # build networks\n",
    "\n",
    "        incoming = self.inputs\n",
    "        layer_nodes = [self.D_input] + self.N_hidden\n",
    "        \n",
    "        #hidden layers\n",
    "        self.hid_layers=[]\n",
    "        \n",
    "        for l in range(self.Layers):\n",
    "            incoming,l2_loss= self.layer(incoming,layer_nodes[l],layer_nodes[l+1],prefix+str(l),act=tf.nn.relu)\n",
    "            self.l2_penalty+=l2_loss\n",
    "            print('Add dense layer: relu with drop_keep:%s' %self.drop_keep)\n",
    "            print('    %sD --> %sD' %(layer_nodes[l],layer_nodes[l+1]))\n",
    "            self.hid_layers.append(incoming)\n",
    "            #drop out layer\n",
    "            incoming = self.drop_layer(incoming)\n",
    "            \n",
    "        #output layer\n",
    "        self.output,l2_loss= self.layer(incoming,layer_nodes[-1],self.D_label, layer_name='output',act=tf.identity)\n",
    "        self.l2_penalty+=l2_loss\n",
    "        print('Add output layer: linear')\n",
    "        print('    %sD --> %sD' %(layer_nodes[-1],self.D_label))\n",
    "        \n",
    "        #loss\n",
    "        if self.Task_type=='regression':\n",
    "            with tf.name_scope('SSE'):\n",
    "                self.loss=tf.reduce_mean(tf.nn.l2_loss((self.output - self.labels)))\n",
    "                tf.scalar_summary('loss', self.loss)\n",
    "        else:\n",
    "            entropy = tf.nn.softmax_cross_entropy_with_logits(self.output, self.labels)\n",
    "            with tf.name_scope('cross entropy'):\n",
    "                self.loss = tf.reduce_mean(entropy)\n",
    "                tf.scalar_summary('loss', self.loss)\n",
    "            with tf.name_scope('accuracy'):\n",
    "                correct_prediction = tf.equal(tf.argmax(self.output, 1), tf.argmax(self.labels, 1))\n",
    "                self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "                tf.scalar_summary('accuracy', self.accuracy)\n",
    "        #train\n",
    "        with tf.name_scope('train'):\n",
    "            self.train_step = tf.train.AdamOptimizer(self.learning_rate).minimize(self.loss + self.l2_penalty*self.L2_lambda)\n",
    "\n",
    "\n",
    "    def shufflelists(self,lists):\n",
    "        ri=np.random.permutation(len(lists[1]))\n",
    "        out=[]\n",
    "        for l in lists:\n",
    "            out.append(l[ri])\n",
    "        return out\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs=[[0,0],[0,1],[1,0],[1,1]]\n",
    "outputs=[0,1,1,0]\n",
    "X=np.array(inputs).reshape((4,1,2)).astype('int16')\n",
    "Y=np.array(outputs).reshape((4,1,1)).astype('int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add dense layer: relu with drop_keep:1.0\n",
      "    2D --> 8D\n",
      "Add output layer: linear\n",
      "    8D --> 1D\n"
     ]
    }
   ],
   "source": [
    "a=FNN(1e-5, 1.0, 1, [8], 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sess.close()\n",
    "sess = tf.InteractiveSession()\n",
    "tf.initialize_all_variables().run()\n",
    "merged = tf.merge_all_summaries()\n",
    "train_writer = tf.train.SummaryWriter('log' + '/train',sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k=0.0\n",
    "for i in range(100000):\n",
    "    k+=1\n",
    "    summary, _ = sess.run([merged,a.train_step],feed_dict={a.inputs:X.reshape((4,2)),a.labels:Y.reshape((4,1)),a.drop_keep_rate:1.0})\n",
    "    train_writer.add_summary(summary, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6.66400979e-09]\n",
      " [  1.00000000e+00]\n",
      " [  1.00000000e+00]\n",
      " [ -6.66403821e-09]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f67b0106e90>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhcAAAFkCAYAAACThxm6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUv8PE8cvuyPwa5AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f67e800ef10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pY=sess.run(a.output,feed_dict={a.inputs:X.reshape((4,2)),a.drop_keep_rate:1.0})\n",
    "print(pY)\n",
    "plt.plot(pY,'o')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
